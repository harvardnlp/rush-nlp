%%% A template to produce a nice-looking Curriculum Vitae.
%%% Kieran Healy <kjhealy@gmail.com>
%%% Most recent version is at http://kjhealy.github.com/kjh-vita
%%%
%%% ------------------------------------------------------------------------
%%% Requirements (should be included in a modern tex distribution):
%%% ------------------------------------------------------------------------
%%% xelatex
%%% fontspec.sty
%%% hyperrref.sty
%%% xunicode.sty
%%% color.sty
%%% url.sty
%%% fancyhdr.sty
%%%
%%% ------------------------------------------------------------------------
%%% Optional
%%% ------------------------------------------------------------------------
%%% git
%%% vc.sty
%%% revnum.sty
%%% Fonts
%%%
%%% ------------------------------------------------------------------------
%%% Note
%%%------------------------------------------------------------------------
%%% Because this is a hand-tweaked file, be on the look out for \medksip,
%%% \bigskip and \newpage commands here and there, which are used to balance
%%% the layout or avoid widows & orphans, etc. You should of course add or
%%% remove these as needed.
%%%------------------------------------------------------------------------

\documentclass[10pt]{article}
\renewcommand{\arraystretch}{1.3}

%%%------------------------------------------------------------------------
%%% Metadata
%%%------------------------------------------------------------------------

%% Change as needed. Or just add me as a coauthor. Only some of these are
%% used below in the hyperref declaration and address banner section.
\def\myauthor{Alexander Rush}
\def\mytitle{Vita}
\def\mycopyright{\myauthor}
\def\mykeywords{}
\def\mybibliostyle{plain}
\def\mybibliocommand{}
\def\mysubtitle{}
\def\myaffiliation{cornell}
\def\myaddress{Computer Science Department}
\def\myemail{arush@cornell.edu}
\def\myweb{http://rush-nlp.com}
\def\myphone{(215) 317-8089}
\def\myfax{srush\_nlp}
\def\myversion{}
\def\myrevision{}


\def\myaffiliation{Cornell University}
\def\myauthor{Alexander Rush}
\date{} % not used (revision control instead)
\def\mykeywords{Rush, Alexander, Alexander Rush, Vita, CV, Resume, Computer Science}

%%%------------------------------------------------------------------------
%%% Git version tracking
%%%------------------------------------------------------------------------

%% If you don't use git or the vc package (from CTAN), comment this out.
%% If you comment it out, be sure to remove the \rfoot comment below, too.
% \input{vc}

%%%------------------------------------------------------------------------
%%% Required style files
%%%------------------------------------------------------------------------
\usepackage{url,fancyhdr}
%%\usepackage{revnum} % for reverse-numbered publications (revnumerate environment) if needed.

%% needed for xelatex to work
% \usepackage{fontspec}
% \usepackage{xunicode}

%% color for the links
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{palatino}
%% hyperlinks
\usepackage[
colorlinks=true,
	urlcolor=BlueViolet,
	plainpages=false,
  	pdfpagelabels,
  	bookmarksnumbered,
  	pdftitle={\mytitle},
  	pagebackref,
  	pdfauthor={\myauthor},
  	pdfkeywords={\mykeywords}
  	]{hyperref}

%%%------------------------------------------------------------------------
%%% Document
%%%------------------------------------------------------------------------
\begin{document}

%% Choose fonts for use with xelatex
%% Minion and Myriad are widely available, from Adobe.
%% Pragmata is available to buy at http://www.fsd.it/fonts/pragma.htm
%% and is worth every penny. Any good monospace font will work fine, though.
%% Consolas or inconsolata are good alternatives.
% \setromanfont[Mapping={tex-text},Numbers={OldStyle},Ligatures={Common}]{arial}
% \setsansfont[Mapping=tex-text,Colour=AA0000]{Myriad Pro}
% \setmonofont[Mapping=tex-text,Scale=0.9]{Inconsolata}


%%%------------------------------------------------------------------------
%%% Local commands
%%%------------------------------------------------------------------------

%% Marginal header
%% Note: as the document goes on you may need to introduce a (gradually increasing)
%% \vspace element to keep the marginal header pleasingly aligned with the first
%% item in the body text. Like this: \marginhead{ {\vskip 0.4em}Grants}, or
%% \marginhead{ {\vskip 0.8em}Service}. Experiment as needed.
\newcommand{\marginhead}[1]{\marginpar{\textsf{ {\footnotesize\vspace{-1em}\flushright #1}}}}


%% custom ampersand (font consistent with the one chosen above)
\newcommand{\amper}{ {\fontspec[Scale=.95,Colour=AA0000]{Minion Pro Medium}\selectfont\&\,}}

%% No bullets on labels
\renewcommand{\labelitemi}{~}

%% Custom hanging indent for vita items
\def\ind{\hangindent=1 true cm\hangafter=1 \noindent}
%\def\ind{\hangindent=18pt\hangafter=1 \noindent}
\def\labelitemi{~}
\renewcommand{\labelitemii}{~}

%%%------------------------------------------------------------------------
%%% Page layout
%%%------------------------------------------------------------------------
\pagestyle{fancy}
\renewcommand{\headrulewidth}{0pt}
\fancyhead{}
\fancyfoot{}
\rhead{ {\scriptsize\thepage}}

%% git revision control footer
%\rfoot{\texttt{\scriptsize \VCRevision\ on \VCDateTEX}} % git revision info inserted via external script -- see docs for vc package for details. comment out this line if you're not using vc, and also remove the \input{vc} line above.

%%%------------------------------------------------------------------------
%%% Address and contact block
%%%------------------------------------------------------------------------
\begin{minipage}[t]{2.95in}
 \flushright {\footnotesize \href{http://rush-nlp.com}{Cornell University} \\ Cornell Tech, \\ \vspace{-0.05in} New York, NY }

\end{minipage}
\hfill
%\begin{minipage}[t]{0.0in}
% dummy (needed here)
%\end{minipage}
\hfill
\begin{minipage}[t]{1.7in}
  \flushright %\footnotesize Phone: \myphone \\
  {\scriptsize  \texttt{\href{mailto:\myemail}{\myemail}}} \\
  {\scriptsize  \texttt{\href{\myweb}{\myweb}}} \\
  {\scriptsize  \texttt{\href{http://twitter.com/\myfax}{@\myfax}}} \\
\end{minipage}


\medskip

%% Name
\noindent{\Large {Alexander M. Rush}}
\reversemarginpar
\medskip


\marginhead{Appointment}
\noindent\emph{Cornell University Computer Science Department \vspace{0.01in}}\\
\ind 2019-.  Associate Professor of Computer Science

\medskip
\noindent\emph{Hugging Face \vspace{0.01in}}\\
\ind 2019-.  NLP Open-Source Startup

\medskip
\noindent\emph{Harvard University School of Engineering and Applied Sciences \vspace{0.01in}}\\
\ind 2015-2019.  Assistant Professor of Computer Science

\medskip
\noindent\emph{Facebook Artificial Intelligence Research Lab \vspace{0.01in}}\\
\ind 2015.  Post-Doctoral Fellowship Advisor: Yann LeCunn

\bigskip

\marginhead{Education}

\noindent\emph{Massachusetts Institute of Technology \vspace{0.01in}}\\
\ind 2009-2014.  Ph.D, Computer Science. Advisor: Michael Collins\\
\ind Dissertation: \emph{Relaxation Methods for Natural Language Decoding}. %\vspace{-0.1in}



\medskip
\noindent\emph{Harvard University\vspace{0.02in}}\\
\ind 2007. B.A., Computer Science.

\bigskip

%% Publications

\marginhead{ {\vskip 0.4em} Awards}
\hspace{-1cm} \begin{tabular}{lp{11.5cm}}
2023 & Best Paper Runner-up -  NeurIPS \\
     & Outstanding Paper -  EMNLP \\
2021 & Best Demo Paper -  EMNLP \\
     & Outstanding Short Paper -  NAACL \\
     & Sloan Fellowship\\
2020 & Best Demo Paper (Runner-Up), ACL   \\
& Best Paper - DAC (Hardware)  \\
& Best Demo Paper - EMNLP  \\
2019 & NSF Career Award \\
& Best Demo Paper - Nominee, ACL   \\
2018 & Senior Program Chair, ICLR  \\
& Best Paper - Runner-Up, VAST (Visualization)  \\
2017 & Best Demo  - Runner-Up, ACL  \\
 & Invitation IJCAI Early Research Spotlight \\
& Best Paper - Runner-Up, EMNLP \\
2015 & NIPS Deep Learning Symposium (Invited Paper)   \\
2012 & Best Paper Award, NAACL \\
2010 & Best Paper Award, EMNLP \\
\end{tabular}


\marginhead{ {\vskip 0.4em} Grants}

\hspace{-1cm} \begin{tabular}{lp{11.5cm}}
2019 & NSF Career Award \\
& Sony Faculty Awards \\
2018& Google, Facebook, and Amazon AWS Faculty Awards \\
2017 & Bloomberg and Intel AI Collaboration Faculty Awards \\
2016 & Microsoft Azure  and Samsung AI Award \\
2015 & Google Faculty Award \\
\end{tabular}
\pagebreak


\bigskip


\marginhead{ {\vskip 0.3em}Publications}

\noindent (Full list: \url{http://bit.do/alexander-rush}) \\

\medskip
\noindent
\textbf{Highly Cited Publications (Google Scholar Metrics)}

\ind Alexander M. Rush, Sumit Chopra, and Jason Weston. \emph{\href{ http://arxiv.org/pdf/1509.00685.pdf }{ A Neural Attention Model for Abstractive Sentence Summarization.} }\emph{ EMNLP 2015. (1600 citations, 3rd Most Cited AAAI Paper 2015-2020) }

\medskip


\ind Yoon Kim, Yacine Jernite, David Sontag, and Alexander M. Rush. \emph{\href{ https://arxiv.org/pdf/1508.06615v4 }{ Character-Aware Neural Language Models.} }\emph{ AAAI 2016, (1250 citations, 3rd Most Cited AAAI Paper 2015-2020) }

\medskip

\ind Hendrik Strobelt, Sebastian Gehrmann, Hanspeter Pfister, and Alexander M. Rush. \emph{\href{ http://lstm.seas.harvard.edu/ }{ LSTMVis: A Tool for Visual Analysis of Hidden State Dynamics in Recurrent Neural Networks.} }\emph{ InfoVis 2017, (139 citations, 12th Most Cited IEEE Transactions on Visualization and Computer Graphics Paper 2015-2020) }



\medskip
\ind Guillaume Klein, Yoon Kim, Yuntian Deng, Jean Senellart, Alexander M. Rush. \emph{\href{ https://arxiv.org/abs/1701.02810 }{ OpenNMT: Open-Source Toolkit for Neural Machine Translation.} }\emph{ ACL Demo 2017 (900 citations, Best Demo Runner-up, 5th Most Cited ACL Paper 2015-2020) }

\medskip

\noindent\textbf{All Conference Papers \vspace{0.01in}}


[1] \ind Celine Lee, Abdulrahman Mahmoud, Michal Kurek, Simone Campanoni, David Brooks, Stephen Chong, Gu-Yeon Wei, Alexander M. Rush. \emph{\href{ https://arxiv.org/pdf/2309.14396.pdf }{ Guess and Sketch: Language Model Guided Transpilation.} }\emph{ Preprint }

\medskip


[2] \ind Lewis Tunstall, Edward Beeching, Nathan Lambert, Nazneen Rajani, Kashif Rasul, Younes Belkada, Shengyi Huang, Leandro von Werra, Clémentine Fourrier, Nathan Habib, Nathan Sarrazin, Omar Sanseviero, Alexander M. Rush, Thomas Wolf. \emph{\href{ https://arxiv.org/pdf/2310.16944.pdf }{ Zephyr: Direct Distillation of LM Alignment.} }\emph{ Preprint }

\medskip


[3] \ind Justin T. Chiu, Wenting Zhao, Derek Chen, Saujas Vaduguru, Alexander M. Rush, Daniel Fried. \emph{\href{ https://arxiv.org/pdf/2310.17140.pdf }{ Symbolic Planning and Code Generation for Grounded Dialogue.} }\emph{ EMNLP 2023 }

\medskip


[4] \ind Zhiying Xu, Francis Y. Yan, Rachee Singh, Justin T. Chiu, Alexander M. Rush, Minlan Yu. \emph{\href{ https://arxiv.org/abs/2210.13763 }{ Teal: Learning-Accelerated Optimization of WAN Traffic Engineering.} }\emph{ SIGCOMM 2023 }

\medskip


[5] \ind John X. Morris, Volodymyr Kuleshov, Vitaly Shmatikov, Alexander M. Rush. \emph{\href{ https://arxiv.org/pdf/2310.06816.pdf }{ Text Embeddings Reveal (Almost) As Much As Text.} }\emph{ EMNLP 2023 }

\medskip


[6] \ind John X. Morris, Chandan Singh, Alexander M. Rush, Jianfeng Gao, Yuntian Deng. \emph{\href{ https://arxiv.org/pdf/2310.14034.pdf }{ Tree Prompting: Efficient Task Adaptation without Fine-Tuning.} }\emph{ EMNLP 2023 }

\medskip


[7] \ind Wenting Zhao, Justin T. Chiu, Claire Cardie, Alexander M. Rush. \emph{\href{ https://arxiv.org/pdf/2305.14237.pdf }{ HOP, UNION, GENERATE: Explainable Multi-hop Reasoning without Rationale Supervision.} }\emph{ EMNLP 2023 }

\medskip


[8] \ind Junxiong Wang, Jing Nathan Yan, Albert Gu, Alexander M. Rush. \emph{\href{ https://arxiv.org/pdf/2212.10544.pdf }{ Pretraining Without Attention.} }\emph{ EMNLP 2023 Findings }

\medskip


[9] \ind Niklas Muennighoff, Alexander M. Rush, Boaz Barak, Teven Le Scao, Aleksandra Piktus, Nouamane Tazi, Sampo Pyysalo, Thomas Wolf, Colin Raffel. \emph{\href{ https://arxiv.org/pdf/2305.16264.pdf }{ Scaling Data-Constrained Language Models.} }\emph{ NeurIPS 2023 (Oral) }

\medskip


[10] \ind Hugo Laurençon, Lucile Saulnier, Léo Tronchon, Stas Bekman, Amanpreet Singh, Anton Lozhkov, Thomas Wang, Siddharth Karamcheti, Alexander M. Rush, Douwe Kiela, Matthieu Cord, Victor Sanh. \emph{\href{ https://arxiv.org/pdf/2306.16527.pdf }{ OBELISC: An Open Web-Scale Filtered Dataset of Interleaved Image-Text Documents.} }\emph{ NeurIPS 2023 Dataset }

\medskip


[11] \ind Wenting Zhao, Justin T. Chiu, Claire Cardie, Alexander M. Rush. \emph{\href{ https://arxiv.org/pdf/2305.14618.pdf }{ Abductive Commonsense Reasoning Exploiting Mutually Exclusive Explanations.} }\emph{ ACL 2023 }

\medskip


[12] \ind Yuntian Deng, Noriyuki Kojima, Alexander M. Rush. \emph{\href{ https://arxiv.org/abs/2210.05147 }{ Markup-to-Image Diffusion Models with Scheduled Sampling.} }\emph{ ICLR 2023 }

\medskip


[13] \ind Thierry Tambe, Jeff Zhang, Coleman Hooper, Tianyu Jia, Paul N. Whatmough, Joseph Zuckerman, Maico Cassel dos Santos, Erik Jens Loscalzo, Davide Giri, Kenneth L. Shepard, Luca P. Carloni, Alexander M. Rush, David Brooks, Gu-Yeon Wei. \emph{\href{ None }{ A 12nm 18.1TFLOPs/W Sparse Transformer Processor with Entropy-Based Early Exit, Mixed-Precision Predication and Fine-Grained Power Management.} }\emph{ ISSCC 2023 }

\medskip


[14] \ind BigScience Workshop. \emph{\href{ https://arxiv.org/abs/2211.05100 }{ BLOOM: A 176B-Parameter Open-Access Multilingual Language Model.} }\emph{ Arxiv Preprint }

\medskip


[15] \ind David Chiang, Alexander M. Rush, Boaz Barak. \emph{\href{ https://arxiv.org/pdf/2102.13196.pdf }{ Named Tensor Notation.} }\emph{ TMLR 2022 }

\medskip


[16] \ind Zhiying Xu, Sivaramakrishnan Ramanathan, Alexander Rush, Jelena Mirkovic, Minlan Yu. \emph{\href{ https://dl.acm.org/doi/abs/10.1145/3555050.3569121 }{ Xatu: boosting existing DDoS detection systems using auxiliary signals.} }\emph{ CoNEXT 2022 }

\medskip


[17] \ind John X Morris, Justin T Chiu, Ramin Zabih, Alexander M Rush. \emph{\href{ https://arxiv.org/pdf/2210.11528.pdf }{ Unsupervised Text Deidentification.} }\emph{ EMNLP Findings 2022 }

\medskip


[18] \ind Yuntian Deng, Volodymyr Kuleshov, Alexander M Rush. \emph{\href{ https://arxiv.org/pdf/2210.08444.pdf }{ Model Criticism for Long-Form Text Generation.} }\emph{ EMNLP 2022 }

\medskip


[19] \ind Leandro von Werra et al.. \emph{\href{ https://arxiv.org/abs/2210.01970 }{ Evaluate and Evaluation on the Hub: Better Best Practices for Data and Model Measurement.} }\emph{ EMNLP Demos 2022 (Best Demo) }

\medskip


[20] \ind Hendik Strobelt et al.. \emph{\href{ https://ieeexplore.ieee.org/abstract/document/9908590 }{ Interactive and Visual Prompt Engineering for Ad-hoc Task Adaptation with Large Language Models.} }\emph{ IEEE Trans on Visualization 2022 }

\medskip


[21] \ind Thierry Tambe et al.. \emph{\href{ https://discovery.ucl.ac.uk/id/eprint/10150658/1/A_16-nm_SoC_for_Noise-Robust_Speech.pdf }{ A 16-nm SoC for Noise-Robust Speech and NLP Edge AI Inference With Bayesian Sound Source Separation and Attention-Based DNNs.} }\emph{ IEEE Solid-State Circuits 2022 }

\medskip


[22] \ind Stephen Bach et al.. \emph{\href{ https://arxiv.org/abs/2202.01279 }{ Promptsource: An integrated development environment and repository for natural language prompts.} }\emph{ ACL Demo 2022 }

\medskip


[23] \ind Samantha Petti, et al.. \emph{\href{ http://repository.cshl.edu/id/eprint/40409/1/2021.Petti.multiple_sequence_alignments.pdf }{ End-to-end learning of multiple sequence alignments with differentiable Smith-Waterman.} }\emph{ Bioinformatics }

\medskip


[24] \ind Victor Sanh, et al.. \emph{\href{ https://arxiv.org/pdf/2110.08207 }{ Multitask prompted training enables zero-shot task generalization.} }\emph{ ICLR 2022 }

\medskip


[25] \ind Stanislav Lukyanenko et al.. \emph{\href{ https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8526069/ }{ Developmental Stage Classification of Embryos Using Two-Stream Neural Network with Linear-Chain Conditional Random Field.} }\emph{ MICCAI 2021 }

\medskip


[26] \ind Keyon Vafa, Yuntian Deng, David Blei, Alexander Rush. \emph{\href{ https://arxiv.org/pdf/2109.06387 }{ Rationales for sequential predictions.} }\emph{ EMNLP 2021 }

\medskip


[27] \ind Justin Chiu, Yuntian Deng, and Alexander M. Rush. \emph{\href{ https://proceedings.neurips.cc/paper/2021/file/16c0d78ef6a76b5c247113a4c9514059-Paper.pdf }{ Low-Rank Constraints for Fast Inference in Structured Models.} }\emph{ NeurIPS 2021 }

\medskip


[28] \ind Matthe Skiles et al.. \emph{\href{ https://www.nature.com/articles/s41893-021-00823-2 }{ Conference demographics and footprint changed by virtual platforms.} }\emph{ Nature Sustainability }

\medskip


[29] \ind Yuntian Deng and Alexander M. Rush. \emph{\href{ https://aclanthology.org/2021.findings-emnlp.318.pdf }{ Sequence-to-Lattice Models for Fast Translation.} }\emph{ EMNLP Findings Short 2021 }

\medskip


[30] \ind Quentin Lhoest et al. \emph{\href{ https://arxiv.org/pdf/2109.02846.pdf }{ Datasets: A Community Library for Natural Language Processing.} }\emph{ EMNLP Demos 2021 (Best Demo) }

\medskip


[31] \ind Thierry Tambe and Others. \emph{\href{ https://arxiv.org/pdf/2011.14203.pdf }{ EdgeBERT: Sentence-Level Energy Optimizations for Latency-Aware Multi-Task NLP Inference.} }\emph{ IEEE MICRO 2021 }

\medskip


[32] \ind Hendrik Strobelt, Jambay Kinley, Robert Krueger, Johanna Beyer, Alexander M. Rush, Hanspeter Pfister. \emph{\href{ None }{ GenNI: Human-AI Collaboration for Data-Backed Text Generation.} }\emph{ IEEE VIS 2021 }

\medskip


[33] \ind Demi Guo, Alexander M. Rush, Yoon Kim. \emph{\href{ https://arxiv.org/pdf/2012.07463.pdf }{ Parameter-efficient transfer learning with diff pruning.} }\emph{ ACL 2021 }

\medskip


[34] \ind Teven Le Scao, Alexander M. Rush. \emph{\href{ https://aclanthology.org/2021.naacl-main.208.pdf }{ How many data points is a prompt worth?.} }\emph{ NAACL Short 2021 (Best Paper - Runner-Up) }

\medskip


[35] \ind François Lagunas, Ella Charlaix, Victor Sanh, Alexander M Rush. \emph{\href{ https://arxiv.org/pdf/2109.04838 }{ Block pruning for faster transformers.} }\emph{ ACL 2021 }

\medskip


[36] \ind Steven Cao, Victor Sanh, Alexander M. Rush. \emph{\href{ https://aclanthology.org/2021.naacl-main.74/ }{ Low-Complexity Probing via Finding Subnetworks.} }\emph{ NAACL Short 2021 }

\medskip


[37] \ind Xinya Du, Alexander M. Rush, Claire Cardie. \emph{\href{ https://aclanthology.org/2021.naacl-main.70/ }{ Template Filling with Generative Transformers.} }\emph{ NAACL Short 2021 }

\medskip


[38] \ind Thierry Tambe, En-Yu Yang, Glenn G Ko, Yuji Chai, Coleman Hooper, Marco Donato, Paul N Whatmough, Alexander M Rush, David Brooks, Gu-Yeon Wei. \emph{\href{ https://ieeexplore.ieee.org/abstract/document/9366062 }{ 9.8 A 25mm2 SoC for IoT Devices with 18ms Noise-Robust Speech-to-Text Latency via Bayesian Speech Denoising and Attention-Based Sequence-to-Sequence DNN Speech Recognition in 16nm FinFET.} }\emph{ IEEE International Solid-State Circuits Conference 2021 }

\medskip


[39] \ind Yuntian Deng, Alexander M. Rush. \emph{\href{ https://arxiv.org/pdf/2006.01112 }{ Cascaded Text Generation with Markov Transformers.} }\emph{ NeurIPS 2020 }

\medskip


[40] \ind Yao Fu, Chuanqi Tan, Bin Bi, Mosha Chen, Yansong Feng, Alexander Rush. \emph{\href{ https://github.com/FranxYao/Gumbel-CRF }{ Latent Template Induction with Gumbel-CRFs.} }\emph{ NeurIPS 2020 }

\medskip


[41] \ind Victor Sanh, Thomas Wolf, Alexander M. Rush. \emph{\href{ https://arxiv.org/pdf/2005.07683 }{ Movement Pruning: Adaptive Sparsity by Fine-Tuning.} }\emph{ NeurIPS 2020 }

\medskip


[42] \ind Justin T. Chiu, Alexander M. Rush. \emph{\href{ https://arxiv.org/abs/2011.04640 }{ Scaling Hidden Markov Language Models.} }\emph{ EMNLP 2020 }

\medskip


[43] \ind Congzheng Song, Alexander M. Rush, Vitaly Shmatikov. \emph{\href{ https://www.cs.cornell.edu/~shmat/shmat_emnlp20.pdf }{ Adversarial Semantic Collisions.} }\emph{ EMNLP 2020 }

\medskip


[44] \ind Demi Guo, Yoon Kim, Alexander M. Rush. \emph{\href{ https://www.aclweb.org/anthology/2020.emnlp-main.447/ }{ Sequence-Level Mixed Sample Data Augmentation.} }\emph{ EMNLP 2020 }

\medskip


[45] \ind Thierry Tambe, En-Yu Yang, Zishen Wan, Yuntian Deng, Vijay Janapa Reddi, Alexander Rush, David Brooks, Gu-Yeon Wei. \emph{\href{ https://arxiv.org/pdf/1909.13271 }{ AdaptivFloat: A Floating-point based Data Type for Resilient Deep Learning Inference.} }\emph{ DAC 2020 (Best Paper) }

\medskip


[46] \ind Thomas Wolf et al. \emph{\href{ https://arxiv.org/pdf/1910.03771 }{ Transformers: State-of-the-art Natural Language Processing.} }\emph{ EMNLP Demos 2020 (Best Demo) }

\medskip


[47] \ind Alexander Rush. \emph{\href{ https://arxiv.org/pdf/2002.00876 }{ Torch-Struct: Deep Structured Prediction Library.} }\emph{ ACL Demos 2020 (Best Demo Honorable Mention) }

\medskip


[48] \ind Noriyuki Kojima, Hadar Averbuch-Elor, Alexander M. Rush, Yoav Artzi. \emph{\href{ https://arxiv.org/pdf/2005.01678 }{ What is Learned in Visually Grounded Neural Syntax Acquisition.} }\emph{ ACL 2020  (Short) }

\medskip


[49] \ind Xiang Lisa Li, Alexander M. Rush. \emph{\href{ https://arxiv.org/pdf/2005.04560 }{ Posterior Control of Blackbox Generation.} }\emph{ ACL 2020 }

\medskip


[50] \ind Jiawei Zhou, Zhiying Xu, Alexander M. Rush, Minlan Yu. \emph{\href{ https://arxiv.org/pdf/2003.06344 }{ Automating Botnet Detection with Graph Neural Networks.} }\emph{ AutoML for Networking and Systems Workshop }

\medskip


[51] \ind Georgios A. Tritsaris, Yiqi Xie, Alexander M. Rush, Stephen Carr, Marios Mattheakis, Efthimios Kaxiras. \emph{\href{ https://arxiv.org/pdf/1910.03413 }{ LAN -- A materials notation for 2D layered assemblies.} }\emph{ None }

\medskip


[52] \ind Udit Gupta, Brandon Reagen, Lillian Pentecost, Marco Donato, Thierry Tambe, Alexander M. Rush, Gu-Yeon Wei, David Brooks. \emph{\href{ None }{ MASR: A Modular Accelerator for Sparse RNNs.} }\emph{ PACT 2019 }

\medskip


[53] \ind Joe Davison, Joshua Feldman and Alexander Rush. \emph{\href{ None }{ Commonsense Knowledge Mining from Pretrained Models.} }\emph{ EMNLP 2019 }

\medskip


[54] \ind Zachary Ziegler, Yuntian Deng and Alexander Rush. \emph{\href{ https://arxiv.org/abs/1909.01496 }{ Neural Linguistic Steganography.} }\emph{ EMNLP 2019 }

\medskip


[55] \ind Yoon Kim,  Chris Dyer, Alexander M. Rush. \emph{\href{ https://www.aclweb.org/anthology/P19-1228/ }{ Compound Probabilistic Context-Free Grammars for Grammar Induction.} }\emph{ ACL 2019 }

\medskip


[56] \ind Gehrmann S, Strobelt H, Krueger R, Pfister H, and Alexander M. Rush. \emph{\href{ https://arxiv.org/abs/1907.10739 }{ Visual Interaction with Deep Learning Models through Collaborative Semantic Inference.} }\emph{ InfoVis 2019 }

\medskip


[57] \ind Jiawei Zhou, Alexander M. Rush. \emph{\href{ https://www.aclweb.org/anthology/P19-1503 }{ Simple Unsupervised Summarization by Contextual Matching.} }\emph{ ACL 2019 }

\medskip


[58] \ind Sebastian Gehrmann, Hendrik Strobelt, Alexander M Rush. \emph{\href{ https://arxiv.org/abs/1906.04043 }{ GLTR: Statistical Detection and Visualization of Generated Text.} }\emph{ ACL Demo 2019 (Best Demo Honorable Mention) }

\medskip


[59] \ind Yoon Kim, Alexander M. Rush, Lei Yu, Adhiguna Kuncoro, Chris Dyer, Gabor Melis. \emph{\href{ https://arxiv.org/pdf/1904.03746.pdf }{ Unsupervised Recurrent Neural Network Grammars.} }\emph{ NAACL 2019 }

\medskip


[60] \ind Adji B. Dieng, Yoon Kim, Alexander M. Rush, David M. Blei. \emph{\href{ https://arxiv.org/pdf/1807.04863.pdf }{ Avoiding Latent Variable Collapse With Generative Skip Models.} }\emph{ AISTATS 2019 }

\medskip


[61] \ind Fritz Obermeyer, Eli Bingham, Martin Jankowiak, Justin Chiu, Neeraj Pradhan, Alexander Rush, Noah Goodman. \emph{\href{ https://arxiv.org/pdf/1902.03210.pdf }{ Tensor Variable Elimination for Plated Factor Graphs.} }\emph{ ICML 2019 }

\medskip


[62] \ind Zachary M. Ziegler, Alexander M. Rush. \emph{\href{ https://arxiv.org/pdf/1901.10548 }{ Latent Normalizing Flows for Discrete Sequences.} }\emph{ ICML 2019 }

\medskip


[63] \ind Yoon Kim, Sam Wiseman, Alexander M. Rush. \emph{\href{ https://github.com/harvardnlp/DeepLatentNLP/raw/master/tutorial_deep_latent.pdf }{ Deep Latent-Variable Models for Natural Language.} }\emph{ EMNLP 2018 (Tutorial) }

\medskip


[64] \ind Sebastian Gehrmann, Falcon Z. Dai, Henry Elder, Alexander M. Rush. \emph{\href{ https://arxiv.org/pdf/1810.04700 }{ End-to-End Content and Plan Selection for Data-to-Text Generation.} }\emph{ INLG 2018 }

\medskip


[65] \ind Yuntian Deng*, Yoon Kim*, Justin Chiu, Demi Guo, Alexander M. Rush. \emph{\href{ https://arxiv.org/pdf/1807.03756.pdf }{ Latent Alignment and Variational Attention.} }\emph{ NIPS 2018 }

\medskip


[66] \ind Sam Wiseman, Stuart M. Shieber, Alexander Rush. \emph{\href{ https://arxiv.org/abs/1808.10122 }{ Learning Neural Templates for Text Generation.} }\emph{ EMNLP 2018 }

\medskip


[67] \ind Sebastian Gehrmann, Yuntian Deng, Alexander Rush. \emph{\href{ https://arxiv.org/abs/1808.10792 }{ Bottom-Up Abstractive Summarization.} }\emph{ EMNLP 2018 }

\medskip


[68] \ind Luke Melas-Kyriazi, George Han, Alexander Rush. \emph{\href{ https://www.aclweb.org/anthology/D18-1084 }{ Training for Diversity in Image Paragraph Captioning.} }\emph{ EMNLP 2018 (Short) }

\medskip


[69] \ind Luong Hoang, Sam Wiseman, Alexander Rush. \emph{\href{ https://www.aclweb.org/anthology/D18-1130 }{ Entity Tracking Improves Cloze-style Reading Comprehension.} }\emph{ EMNLP 2018 (Short) }

\medskip


[70] \ind Hendrik Strobelt, Sebastian Gehrmann, Michael Behrisch, Adam Perer, Hanspeter Pfister, Alexander M. Rush. \emph{\href{ https://arxiv.org/abs/1804.09299 }{ Seq2Seq-Vis: A Visual Debugging Tool for Sequence-to-Sequence Models .} }\emph{ VAST 2018, EMNLP-BlackBox 2018 (Best Paper - Honorable Mention) }

\medskip


[71] \ind Alexander M. Rush. \emph{\href{ http://aclweb.org/anthology/W18-2509 }{ The Annotated Transformer.} }\emph{ ACL NLP-OSS 2018 }

\medskip


[72] \ind Jean Senellart, Dakun Zhang, Bo Wang, Guillaume Klein, J.P. Ramatchandirin, Josep Crego, Alexander M. Rush. \emph{\href{ http://aclweb.org/anthology/W18-2715 }{ OpenNMT System Description for WNMT 2018: 800 words/sec on a single-core CPU.} }\emph{ WNMT 2018  (First-Place CPU Speed/Memory) }

\medskip


[73] \ind Yoon Kim, Sam Wiseman, Andrew C. Miller, David Sontag, Alexander M. Rush. \emph{\href{ https://arxiv.org/abs/1802.02550 }{ Semi-Amortized Variational Autoencoders.} }\emph{ ICML 2018 }

\medskip


[74] \ind Brandon Reagen, Udit Gupta, Robert Adolf, Michael M. Mitzenmacher, Alexander M. Rush, Gu-Yeon Wei, David Brooks. \emph{\href{ https://www.sysml.cc/doc/68.pdf }{ Compressing Deep Neural Networks with Probabilistic Data Structures.} }\emph{ ICML 2018, SysML 2018 }

\medskip


[75] \ind Allen Schmaltz, Yoon Kim, Alexander M. Rush, Stuart M. Shieber. \emph{\href{ https://arxiv.org/abs/1707.09067 }{ Adapting Sequence Models for Sentence Correction.} }\emph{ EMNLP 2017 }

\medskip


[76] \ind Sam Wiseman, Stuart M Shieber Alexander M. Rush. \emph{\href{ https://arxiv.org/abs/1707.08052 }{ Challenges in Data-to-Document Generation.} }\emph{ EMNLP 2017 }

\medskip


[77] \ind Junbo Zhao, Yoon Kim, Kelly Zhang, Alexander M. Rush, Yann LeCun. \emph{\href{ https://arxiv.org/abs/1706.04223 }{ Adversarially Regularized Autoencoders.} }\emph{ ICML 2018, NIPS 2017 Workshop }

\medskip


[78] \ind Guillaume Klein, Yoon Kim, Yuntian Deng, Jean Senellart, Alexander M. Rush. \emph{\href{ https://arxiv.org/abs/1701.02810 }{ OpenNMT: Open-Source Toolkit for Neural Machine Translation.} }\emph{ ACL Demo 2017 (Best Demo Runner-up) }

\medskip


[79] \ind Ankit Gupta, Alexander M. Rush. \emph{\href{ https://arxiv.org/abs/1710.01278 }{ Dilated Convolutions for Modeling Long-Distance Genomic Dependencies.} }\emph{ ICML CompBio 2017 (Best Poster) }

\medskip


[80] \ind Yuntian Deng, Anssi Kanervisto, Jeffrey Ling, and Alexander M. Rush. \emph{\href{ http://lstm.seas.harvard.edu/latex/ }{ Image-to-Markup Generation with Coarse-to-Fine Attention.} }\emph{ ICML 2017 }

\medskip


[81] \ind Hendrik Strobelt, Sebastian Gehrmann, Hanspeter Pfister, and Alexander M. Rush. \emph{\href{ http://lstm.seas.harvard.edu/ }{ LSTMVis: A Tool for Visual Analysis of Hidden State Dynamics in Recurrent Neural Networks.} }\emph{ InfoVis 2017 }

\medskip


[82] \ind Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. \emph{\href{ https://arxiv.org/abs/1702.00887 }{ Structured Attention Networks.} }\emph{ ICLR 2017 }

\medskip


[83] \ind Greg Yang and Alexander M. Rush. \emph{\href{ http://lstm.seas.harvard.edu/lantm/ }{ Lie-Access Neural Turing Machines.} }\emph{ ICLR 2017 }

\medskip


[84] \ind Yoon Kim and Alexander M. Rush. \emph{\href{ http://arxiv.org/pdf/1606.07947v1.pdf }{ Sequence-Level Knowledge Distillation.} }\emph{ EMNLP 2016 }

\medskip


[85] \ind Sam Wiseman and Alexander M. Rush. \emph{\href{ http://arxiv.org/pdf/1606.02960.pdf }{ Sequence-to-Sequence Learning as Beam-Search Optimization.} }\emph{ EMNLP 2016 (Best Paper Runner-Up) }

\medskip


[86] \ind Peter Kraft, Hirsh Jain, and Alexander M. Rush. \emph{\href{ https://www.aclweb.org/anthology/D/D16/D16-1221.pdf }{ An Embedding Model for Predicting Roll-Call Votes.} }\emph{ Proceedings of EMNLP 2016 }

\medskip


[87] \ind Allen Schmaltz, Alexander M. Rush, and Stuart M. Shieber. \emph{\href{ https://arxiv.org/abs/1604.08633 }{ Word Ordering Without Syntax.} }\emph{ EMNLP 2016 }

\medskip


[88] \ind Allen Schmaltz, Yoon Kim, Alexander M. Rush, and Stuart M. Shieber. \emph{\href{ /papers/aesw2016.pdf }{ Sentence-Level Grammatical Error Identification as Sequence-to-Sequence Correction.} }\emph{ Workshop Submission for AESW 2016 (Top Performing System) }

\medskip


[89] \ind Sam Wiseman, Alexander M. Rush, and Stuart M. Shieber. \emph{\href{ /papers/corefmain.pdf }{ Learning Global Features for Coreference Resolution.} }\emph{ NAACL 2016 }

\medskip


[90] \ind Sumit Chopra, Michael Auli, and Alexander M. Rush. \emph{\href{ /papers/naacl16_summary.pdf }{ Abstractive Sentence Summarization with Attentive Recurrent Neural Networks.} }\emph{ NAACL 2016 }

\medskip


[91] \ind Yoon Kim, Yacine Jernite, David Sontag, and Alexander M. Rush. \emph{\href{ https://arxiv.org/pdf/1508.06615v4 }{ Character-Aware Neural Language Models.} }\emph{ AAAI 2016 }

\medskip


[92] \ind Alexander M. Rush, Sumit Chopra, and Jason Weston. \emph{\href{ http://arxiv.org/pdf/1509.00685.pdf }{ A Neural Attention Model for Abstractive Sentence Summarization.} }\emph{ EMNLP 2015. }

\medskip


[93] \ind Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, and Alexander M. Rush. \emph{\href{ http://arxiv.org/pdf/1502.05698.pdf }{ Towards AI-Complete Question Answering A Set of Prerequisite Toy Tasks.} }\emph{ ArXiv Preprint }

\medskip


[94] \ind Sam Wiseman, Alexander M. Rush, Jason Weston, and Stuart M. Shieber. \emph{\href{ http://people.seas.harvard.edu/~srush/acl15.pdf }{ Learning Anaphoricity and Antecedent Ranking Features for Coreference Resolution.} }\emph{ ACL 2015. }

\medskip


[95] \ind Yacine Jernite, Alexander M. Rush, and David Sontag. \emph{\href{ http://people.seas.harvard.edu/~srush/icml15.pdf }{ A Fast Variational Approach for Learning Markov Random Field Language Models.} }\emph{ ICML 2015. }

\medskip


[96] \ind Lingpeng Kong, Alexander M. Rush, and Noah A. Smith. \emph{\href{ http://people.seas.harvard.edu/~srush/naacl15.pdf }{ Transforming Dependencies into Phrase Structures.} }\emph{ NAACL 2015. }

\medskip




[97] \ind Yin-Wen Chang, Alexander M. Rush, John DeNero, and Michael Collins.. \emph{\href{ http://people.csail.mit.edu/srush/ }{ A Lagrangian Relaxation Algorithm for Bilingual Word Alignment.} }\emph{ Proceedings of ACL 2014. }

[98] \ind Alexander M. Rush, Yin-Wen Chang, and Michael Collins.. \emph{\href{ None }{ Optimal Beam Search for Machine Translation.} }\emph{ Proceedings of EMNLP 2013. }

[99] \ind Karl Stratos, Alexander M. Rush, Shay B. Cohen, and Michael Collins.. \emph{\href{ http://www.cs.columbia.edu/~stratos/research/conll13rhmm.pdf }{ Spectral Learning of Refinement HMMs.} }\emph{ Proceedings of CoNLL 2013. }

[100] \ind Alexander M. Rush, Roi Reichert, Michael Collins, and Amir Globerson.. \emph{\href{ http://people.csail.mit.edu/srush/emnlp2012.pdf.pdf }{ Improved Parsing and POS Tagging Using Inter-Sentence Consistency Constraints.} }\emph{ Proceedings of EMNLP 2012. }

[101] \ind Alexander M. Rush and Slav Petrov. \emph{\href{ http://people.csail.mit.edu/srush/vine-paper.pdf }{ Vine Pruning for Efficient Multi-Pass Dependency Parsing.} }\emph{ Proceedings of NAACL 2012. (Best Paper Award) }

[102] \ind Alexander M. Rush and Michael Collins.. \emph{\href{ http://people.csail.mit.edu/srush/exdecmt.pdf }{ Exact Decoding of Syntactic Translation Models through Lagrangian Relaxation.} }\emph{ Proceedings of ACL 2011. }

[103] \ind Terry Koo, Alexander M. Rush, Michael Collins, Tommi Jaakkola, and David Sontag.. \emph{\href{ http://people.csail.mit.edu/maestro/papers/koo10mstdd.pdf }{ Dual Decomposition for Parsing with Non-Projective Head Automata.} }\emph{ Proceedings of EMNLP 2010. }

[104] \ind Alexander M. Rush, David Sontag, Michael Collins, and Tommi Jaakkola. \emph{\href{ http://people.csail.mit.edu/dsontag/papers/RusSonColJaa_emnlp10.pdf }{ On Dual Decomposition and Linear Programming Relaxations for Natural Language Processing.} }\emph{ Proceedings of EMNLP 2010. }

[105] \ind Rebecca Nesson, Stuart M. Shieber, and Alexander M. Rush.. \emph{\href{ http://www.eecs.harvard.edu/~shieber/Biblio/Papers/Nesson-2006-IPS.pdf }{ Induction of probabilistic synchronous tree-insertion grammars for machine translation.} }\emph{ Proceedings of AMTA 2006. }


\vspace{0.3in}

\noindent\emph{Journal Papers \vspace{0.01in}}

\ind Alexander M. Rush and Michael Collins. \emph{\href{http://www.cs.columbia.edu/~mcollins/acltutorial.pdf}{A Tutorial on Dual Decomposition and Lagrangian Relaxation for Inference in Natural Language Processing}}. Journal of Artificial Intelligence Research 2012.



% %\end{revnumerate}
% \begin{itemize} \itemsep -2pt %
% \item Helped develop optimized C++ parser and interpreter for FBML, a domain-specific markup language for applications.

% \medskip

% \item Built and designed a distributed system for tracking resource constraints of third-party applications. Awarded patent.
% \medskip

% \item Contributor on Internationalization project which utilizes crowd-sourcing to translate Facebook into 70+ languages.
% \end{itemize}

% \ind Technical Associate (Intern), {\sl Bridgewater Associates}  June -- September 2006,
%  Westport, CT. Implemented trade scheduling and equity analysis algorithms.
% \begin{itemize} \itemsep -2pt % Reduce space between items
% \item Designed and implemented large-scale trade scheduling and equity analysis algorithms.
% \end{itemize}


\marginhead{ {\vskip 0.4em}Professional Service}
\medskip


\bigskip

\ind Secretary:
\ind ICLR Board 2021-2024

\ind General  Chair:
\ind ICLR (Deep Learning) 2020

\ind Senior Program Chair:
\ind ICLR (Deep Learning) 2019

\ind Senior Area Chair:
\ind TACL 2020; NeurIPS 2019; ACL (Generation) 2019; ACL (Generation) 2020

\ind Area Chair:
\ind NAACL (Machine Learning) 2020; NIPS 2018; NAACL (Machine Learning) 2016; ICLR (NLP) 2017, 2018; EMNLP (Generation/Summarization) 2017; ACL (Parsing and Tagging) 2017

\ind Tutorial Chair: NAACL 2016

\bigskip

\marginhead{ {\vskip 0.4em} Graduate Field Activity}
\medskip

\ind Field Member - Computer Science

\ind PhD Students


\ind Graduated Harvard Students

\begin{itemize}
\item Sam Wiseman (2019); Assistant Professor, Duke University
\item Yoon Kim (2020); Assistant Professor, MIT
\item Sebastian Gehrmann (2020); Google NLP
\end{itemize}

\ind Current Harvard Students

\begin{itemize}
\item Yuntian Deng (Target 2022)
\item Jiawei Zhou (Target 2022)
\end{itemize}

\ind Current Cornell Students

\begin{itemize}
\item Justin Chiu (Target 2023)
\item Jack Morris (Admitted)
\item Woojeong Kim (Admitted)
\item Celine Lee (Admitted)
\end{itemize}

\ind Former Undergraduate Students

\begin{itemize}
\item Demi Guo (Stanford)
\item Lisa Li (Stanford)
\item Keyon Vafa (Columbia)
\item Rachit ()

\end{itemize}


\marginhead{ {\vskip 0.4em}University Service}
\medskip

\ind Program Director 2020-; Computer Science Program, the largest Masters program at Cornell Tech.

\ind Admissions Committee 2020
\bigskip


\marginhead{ {\vskip 0.3em}Teaching}

\hspace{-1cm} \begin{tabular}{lp{11.5cm}}
2021 & \ind  Instructor, Topics in Machine Learning and NLP (10 students) , Cornell Tech, Spring. \\
2020 & \ind  Instructor, Topics in Machine Learning and NLP (100 students), Cornell Tech, Spring. \\
     & \ind  Instructor,  Machine Learning Engineering (100 students) (Rated 4.75/5), Cornell Tech, Fall. \\

                2019 & \ind  Instructor, Machine Learning for NLP (50 students) , Harvard University, Spring. \\

2018 & \ind  Instructor, Machine Learning for NLP (50 students) (Rated 4.8/5) , Harvard University, Spring. \\
& \ind  Instructor, Advanced Machine Learning (100 students), Harvard University, Fall. \\
2017 & \ind  Instructor, Machine Learning (250 students), Harvard University, Spring. \\
& \ind  Instructor, Advanced Machine Learning (100 students), Harvard University, Fall. \\
2016 & \ind  Instructor, Machine Learning for NLP (50 students) (Rated 4.9/5), Harvard University, Spring. \\
2015 & \ind  Instructor, Artificial Intelligence (100 students), Harvard University, Fall. \\
2013 & \ind  Instructor (with Michael Collins), Natural Language Processing, Columbia University, Fall. \\
& \ind Head Teaching Assistant, Natural Language Processing , Michael Collins, Columbia University, Spring (taught on Coursera, 30,000+ registered students). \\
2012 & \ind Head Teaching Assistant, Natural Language Processing, Michael Collins, Columbia University, Fall.\\
\end{tabular}

 \bigskip
\marginhead{ {\vskip 0.3em}Patents}

% \medskip
\ind A neural attention model for abstactive summarization (Facebook). Alexander M. Rush, Sumit Chopra, Jason Weston 2017.
\medskip

\ind Techniques for discriminative dependency parsing (Google). Slav Petrov, Alexander M. Rush, 2015.
\medskip

\ind Efficient parsing with structured prediction cascades (Google). Slav Petrov, Alexander M. Rush, 2013
\medskip

%% Publications
\ind  Determining user affinity towards applications on a social networking website (Facebook., Thomas S. Whitnah, Alexander M. Rush, Ding Zhou, Ruchi Sangvhi, 2010.



\bigskip

%% Publications

\marginhead{ {\vskip 0.4em}Personal Libraries}
\bigskip

\ind \href{ paper.link } { Llama2 Rust. }
\begin{itemize}
\item llama2 in rust.
\end{itemize}
\medskip


\ind \href{ paper.link } { LLM Training Puzzles. }
\begin{itemize}
\item puzzles for learning about distributed training.
\end{itemize}
\medskip


\ind \href{ paper.link } { Thinking Like Transformers. }
\begin{itemize}
\item learn to think like a transformers.
\end{itemize}
\medskip


\ind \href{ paper.link } { GPU-Puzzles. }
\begin{itemize}
\item A series of puzzles for learning about the core aspects of modern deep learning coding. Includes puzzles for tensors, gpu's, and auto-differentiation..
\end{itemize}
\medskip


\ind \href{ paper.link } { Annotated S4. }
\begin{itemize}
\item Annotated S4 is a pedagogical implementation of the S4 model for very long range sequnece modeling utilizing JAX as a method for explaining mathematically complex code..
\end{itemize}
\medskip


\ind \href{ paper.link } { PromptSource. }
\begin{itemize}
\item PromptSource is an IDE for producing natural language prompts on real datasets. It was the basis of the T0 model for large-scale multitask training..
\end{itemize}
\medskip


\ind \href{ paper.link } { Break Through AI. }
\begin{itemize}
\item Break Through AI is a free summer program for supporting female undergraduates to learn AI and ML skills in an applied environment. I teach an 8 week summer program on the core elements on ML in a coding first environment..
\end{itemize}
\medskip


\ind \href{ paper.link } { MiniConf. }
\begin{itemize}
\item MiniConf is a project developed for ICLR as an easy-to-use tool for hosting fully remote asynchronous virtual conferences. It was heavily used in 2020 to host ACL, ICML, AKBC, AIStats, EMNLP, NeurIPS, and many other virtual conferences..
\end{itemize}
\medskip


\ind \href{ paper.link } { MiniTorch. }
\begin{itemize}
\item MiniTorch is a DIY teaching library to walkthrough the process of building a tensor, autodifferentiation library from scratch. It is used to teach machine learning engineering at Cornell Tech..
\end{itemize}
\medskip


\ind \href{ paper.link } { Streambook. }
\begin{itemize}
\item Streambook is a literate programming environment designed to make it easy to write publishable Jupyter notebooks without ever having to open a browser or break your github flow..
\end{itemize}
\medskip


\ind \href{ paper.link } { Named Tensor Notation. }
\begin{itemize}
\item Named Tensor Notation was a follow-up to the named tensor proposal to develop a mathematical notation for more explicit multi-dimensional dot products when describing neural network interactions..
\end{itemize}
\medskip


\ind \href{ paper.link } { NLP Browser. }
\begin{itemize}
\item NLP Browser is a web app that lets any easily browse through more than 150 datasets used in NLP and hosted by Hugging Face. The app is a pretty addictive way to casually learn about new datasets and challenges..
\end{itemize}
\medskip


\ind \href{ paper.link } { NamedTensor (Tensor Considered Harmful). }
\begin{itemize}
\item Named Tensor is a proposal for adding a new datastructure to mathematical libraries to tread tensors more like dicts and less like tuples. This blog post had the impact of getting PyTorch to add a NamedTensor annotation in v1.3 of the libary..
\end{itemize}
\medskip


\ind \href{ paper.link } { Torch Struct. }
\begin{itemize}
\item Torch-Struct is a passion project of mine to test out whether deep learning libraries can be used to implement classical structured prediction. It includes heavily-tested reference reimplementations of many core NLP algorithms..
\end{itemize}
\medskip


\ind \href{ paper.link } { OpenNMT. }
\begin{itemize}
\item A full service open-source neural machine translation system. Originally developed in Lua with Systran, since ported to PyTorch and TensorFlow and maintained externally..
\end{itemize}
\medskip


\ind \href{ paper.link } { The Annotated Transformer. }
\begin{itemize}
\item The annotated transformer was an experiment in blogging based on literate papers. The idea was to teach researchers how an important model in NLP works by aligning the paper line-by-line with an implementation. The blog post was widely distributed, and there have been many follow-ups for new model..
\end{itemize}
\medskip





% \medskip \ind \href{ http://seq2seq-vis.io/ }{ LSTMVis / Seq2Seq-Vis }
% \begin{itemize}
% \item Collaboration with IBM to develop an interactive visualization for translation models.
% \end{itemize}



% \medskip \ind \href{ http://opennmt.net }{ OpenNMT }
% \begin{itemize}
% \item  Open-source neural machine translation system. Used in over 200 publications, and
%   deployed by major translation providers such as Systran International.
% \end{itemize}



% \medskip \ind \href{ http://nlp.seas.harvard.edu/2018/04/03/attention.html }{ The Annotated Transformer }
% \begin{itemize}
% \item  An educational line-by-Line implementation of Google's Transformer architecture.
%   Viewed over 300,000 times.
% \end{itemize}

% \medskip \ind \href{ http://nlp.seas.harvard.edu/NamedTensor }{ Named Tensor }
% \begin{itemize}
% \item  An educational view of the use of tensors in Pytorch.
%     Viewed over 50,000 times over the year.
% \end{itemize}


% 
% 
% \medskip \ind \href{ https://github.com/srush/llama2-rs }{ Llama2 Rust }
% \begin{itemize}
% \item  llama2 in rust
% \end{itemize}
% 

% 
% \medskip \ind \href{ https://github.com/srush/LLM-Training-Puzzles }{ LLM Training Puzzles }
% \begin{itemize}
% \item  puzzles for learning about distributed training
% \end{itemize}
% 

% 
% \medskip \ind \href{ https://srush.github.io/raspy/ }{ Thinking Like Transformers }
% \begin{itemize}
% \item  learn to think like a transformers
% \end{itemize}
% 

% 
% \medskip \ind \href{ https://github.com/srush/gpu-puzzles }{ GPU-Puzzles }
% \begin{itemize}
% \item  puzzles for learning gpu
% \end{itemize}
% 

% 
% \medskip \ind \href{ https://github.com/srush/annotated-s4 }{ Annotated S4 }
% \begin{itemize}
% \item  s4 implementation
% \end{itemize}
% 

% 

% 

% 

% 

% 

% 

% 

% 

% 

% 

% 

% 

% 

% 

% 

% 

% 

% 

% 

% 

% 

% 

% 

% 

% 

% 


 \bigskip


%% Publications


%% Publications

\marginhead{ {\vskip 0.4em}Academic \newline Internships}

\bigskip

\ind Research Intern, {\sl Google Research}, 2011 -- 2013 , New York, NY.  Advisor: Slav Petrov.



\ind Research Intern, {\sl USC/ISI },  Summer 2010, Marina Del Rey, CA. Advisor: Liang Huang.

\bigskip

%% Publications

\marginhead{ {\vskip 0.4em}Industry }

\medskip
\ind  Lead Engineer (Platform Team), {\sl Facebook}, 2007 -- 2009, Palo Alto, CA.
\begin{itemize}
\item Developed compiler for Facebook Markup Language (FBML) to sanitize user content.
\item Developed system for crowd-sourced translation of Facebook user text.
\end{itemize}



% \medskip \ind \href{http://www.pydecode.org}{PyDecode} (http://www.pydecode.org)
% \begin{itemize}
% \item  An optimized toolkit for designing inference algorithms for NLP.
% \end{itemize}

% \ind  \href{http://www.declassification-engine.org}{The Declassification Engine} (http://www.declassification-engine.org)
% \begin{itemize}
% \item  Computational social science project analyzing the process of official secrecy.
% \item Awarded a Magic grant from Brown Institute for Media Innovation.
% \end{itemize}
% \medskip

\bigskip

\marginhead{ {\vskip 0.4em}Invited Talks \newline}
\medskip
\hspace{-1cm} \begin{tabular}{lp{11.5cm}}
                2023
                & \ind   Panel, NeurIPS Keynote. \\
                & \ind   Invited Talk, JHU. \\
                & \ind   Invited Talk, NYU. \\
                & \ind   Keynote Talk, MLSys 2023. \\
                & \ind   Keynote Talk, Simon Workshop on LLMs . \\
                & \ind   Invited Talk, Dagstuhl Seminar. \\
                & \ind   Invited Talk, UCSD AI Seminar. \\
                & \ind   Invited Talk, Penn NLP Seminar. \\
                & \ind   Invited Talk, Stanford NLP Seminar. \\
                2022
                & \ind   Invited Talk, SoCal NLP. \\
                & \ind   Invited Talk, LXMLS 2022. \\
                & \ind   Invited Talk, MASC 2022. \\
                & \ind   Invited Talk, Rutgers Efficient ML. \\
                & \ind   Invited Talk, Georgia Tech NLP Seminar. \\
                & \ind   Invited Talk, Pacific Research Lab NLP. \\
                2021
                & \ind   Invited Talk, NeurIPS Crowd Source ML. \\
                & \ind   Invited Talk, NeurIPS AIPLANs Workshop. \\
                & \ind   Invited Talk, Microsoft Efficient ML. \\
                & \ind   Invited Talk, Stanford SysML. \\
                & \ind   Invited Talk, Lisbon Machine Learning. \\
                 & \ind   Invited Talk, University of Cambridge. \\
                 & \ind   Invited Talk, Oracle. \\
                 & \ind   Invited Talk, UCSB. \\
                2020
                 & \ind   Invited Talk, ByteDance. \\
                 & \ind   Invited Talk, Baidu. \\
                 & \ind   Colloquium, UMass Lowell. \\
                 & \ind   Invited Talk, London Machine Learning. \\
                 & \ind   Invited Talk, UCSB. \\
                 & \ind   Invited Talk, Baidu. \\
                 & \ind   Invited Talk, Google AI. \\
                 & \ind   Invited Talk, Oracle AI. \\
                 & \ind   Invited Talk, EMNLP Structured Prediction WS. \\
                 & \ind   Invited Talk, EMNLP SustaiNLP WS. \\
              \end{tabular}

\hspace{-1cm} \begin{tabular}{lp{11.5cm}}
                2019
                & \ind   Colloquium, University of Edinburgh, Spring.\\
                & \ind   Colloquium, Tel Aviv University, Spring. \\
                 & \ind   Invited Talk, Conversational Intelligence Summer. \\
                & \ind   Invited Talk, GANocracy, MIT, Summer. \\
                & \ind   Invited Talk, OpenAI, MIT, Summer. \\
                & \ind   Invited Talk, NeuralGen Workshop NAACL Summer. \\
                & \ind   Invited Talk, Berkeley NLP, Fall.\\
                & \ind   Keynote, PyTorch Developers Conference, Fall. \\
              \end{tabular}

\hspace{-1cm} \begin{tabular}{lp{11.5cm}}
                2018
 & \ind   Invited Talk, University of Washington, Spring. \\
 & \ind   Invited Talk, Allen Institute for AI, Spring. \\
 & \ind   Invited Talk, MSR, Spring. \\
 & \ind   Keynote, American Machine Translation Association, Spring. \\
 & \ind   Invited Talk, University of Texas, Spring. \\
 & \ind   Invited Talk, University of Maryland, Spring. \\
 & \ind   Invited Talk, Georgetown, Spring. \\
 & \ind   Invited Talk, Lisbon ML Summer School, Summer. \\
 & \ind   Invited Talk, Columbia University, Fall. \\
 & \ind   Invited Talk, New York University - Text as Data, Fall. \\
 & \ind   Tutorial, EMNLP, Fall. \\
              \end{tabular}

\hspace{-1cm} \begin{tabular}{lp{11.5cm}}
2017
 & \ind   Invited Talk, Google Faculty Day, Spring. \\
 & \ind   Invited Talk, New England Machine Learning Day, Spring. \\
 & \ind   Invited Talk, Google, Spring. \\
 & \ind   Invited Talk, Berkeley CS, Spring. \\
 & \ind   Invited Talk, Notre Dame, Spring. \\
 & \ind   Colloquium, TTI-Chicago, Spring. \\
 & \ind   Invited Talk, Apple, Siri Team, Spring. \\
 & \ind   Colloquium, Samsung Global AI Forum, Fall. \\
 & \ind   Invited Talk, AMD, Fall. \\
              \end{tabular}

\hspace{-1cm} \begin{tabular}{lp{11.5cm}}
 2016
 & \ind   Invited Talk, NYU, Fall. \\
 & \ind   Invited Talk, BBN Research, Fall. \\
 & \ind   Invited Talk, Bloomberg, Fall. \\
 & \ind   Invited Talk (Speech Group), MIT, Fall. \\
 & \ind   Invited Talk, IBM Research, Fall. \\
 & \ind   Colloquium, CMU, Fall. \\
 & \ind   Invited Talk, Stanford NLP, Summer. \\
 & \ind   Invited Talk, Oracle Labs, Summer. \\
 & \ind   Invited Talk, Twitter, Summer. \\
 & \ind   Colloquium, John Hopkins University, Spring. \\
 & \ind   Colloquium, Rakuten, Spring. \\
\end{tabular}
\begin{tabular}{lp{11.5cm}}

 2014

 & \ind   Colloquium, University of Washington, Spring. \\

 & \ind   Colloquium, NYU, Spring. \\

 & \ind   Colloquium, CMU, Spring. \\

 & \ind   Colloquium, MIT, Spring. \\

 & \ind   Colloquium, Harvard, Spring. \\

 & \ind   Colloquium, TTIC, Spring. \\

 & \ind   Colloquium, University of Maryland, Spring. \\
\end{tabular}
\hspace{-1cm} \begin{tabular}{lp{11.5cm}}
 2013
 & \ind   Invited Tutorial, UMBC, October. \\

 & \ind   Invited Talk, CS and Social Science Seminar, UMass Amherst, October. \\

 & \ind   Talk, NLP Seminar, Columbia University, October. \\
 & \ind   Invited Talk, ML Seminar, UMass Amherst, October. \\

  & \ind  Invited Talk, Johnson Research Labs, NY, August. \\

  &  \ind Invited Talk, Society for Historians of American Foreign Relations, Arlington, June. \\

  & \ind  Invited Talk, Columbia University, Spring. \\

  &  \ind    Invited Talk, NLP Seminar, City University of New York, Spring. \\
 2012 & \ind   Invited Tutorial, Neural Information Processing Systems (NIPS), December. \\
 2011 & \ind  Invited Tutorial, Google Research, Mountain View, August. \\
  &  \ind Tutorial. Association of Computational Linguistic (ACL), June. \\
  & \ind  Invited Talk, ML Seminar, University of Massachusetts, Amherst, Spring. \\
 & \ind   ML Tea, MIT, January. \\
  2010 & \ind  NLP Seminar, USC/ISI, Summer. \\
 2006 &  \ind  Invited Talk, Computational Linguistics Seminar, University of Pennsylvania, November. \\
\end{tabular}
%\end{revnumerate}


%\newpage


\bigskip

%% Publications

% \marginhead{ {\vskip 0.4em}Misc}
% \medskip

% \ind General Manager of Harvard Radio Broadcasting (WHRB).

% \medskip

% \ind Member ACM Programming Team, Harvard University.

% \medskip

% \ind Experienced in C/C++, Python, Javascript, Lua/Torch, Haskell, Java, PHP, OCaml, LaTeX, HTML/CSS.

\end{document}
